{"cells":[{"cell_type":"markdown","metadata":{"id":"OSNalI24GyjT"},"source":["# Notes\n","\n","This assignment is devoted to `pandas`. It covers indexing and filtering, and some `groupby` and `join` operations. The assignment roughly corresponds to Week 4 and the beginning of Week 5 of the course.\n","\n","The main dataset you'll be using is [Titanic](https://www.kaggle.com/c/titanic). Please, note, that you must not rely on any specific location for the dataset, hence, any code like\n","\n","```python\n","titanic_train = pd.read_csv(\"<location>/train.csv\")\n","```\n","\n","will fail and your notebook won't be validated and graded. Inputs to the functions are described explicitly in each case, and that's the only thing you can rely on."]},{"cell_type":"code","execution_count":30,"metadata":{"ExecuteTime":{"end_time":"2019-12-12T07:42:25.600794Z","start_time":"2019-12-12T07:42:25.049149Z"},"id":"FhY3Y4Z4GyjX","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Populating the interactive namespace from numpy and matplotlib\n"]}],"source":["%pylab inline\n","plt.style.use(\"bmh\")"]},{"cell_type":"code","execution_count":31,"metadata":{"ExecuteTime":{"end_time":"2019-12-12T07:42:25.610011Z","start_time":"2019-12-12T07:42:25.605263Z"},"id":"r5cLFNRTGyjY"},"outputs":[],"source":["plt.rcParams[\"figure.figsize\"] = (6,6)"]},{"cell_type":"code","execution_count":32,"metadata":{"ExecuteTime":{"end_time":"2019-12-12T07:42:26.294404Z","start_time":"2019-12-12T07:42:25.864539Z"},"id":"3CDZ-awAGyjZ","scrolled":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":33,"metadata":{"ExecuteTime":{"end_time":"2019-12-12T07:42:27.329433Z","start_time":"2019-12-12T07:42:27.323905Z"},"id":"DsH4M7OhGyjZ","tags":["parameters"]},"outputs":[],"source":["STUDENT = \"Itay Koren\"\n","ASSIGNMENT = 4\n","TEST = False"]},{"cell_type":"code","execution_count":34,"metadata":{"ExecuteTime":{"end_time":"2019-12-12T07:42:27.767876Z","start_time":"2019-12-12T07:42:27.757195Z"},"id":"9ml9ljtgGyja"},"outputs":[],"source":["if TEST:\n","    import solutions\n","    total_grade = 0\n","    MAX_POINTS = 16"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["titanic_train = pd.read_csv('train.csv', index_col='PassengerId')\n","titanic_test = pd.read_csv('test.csv', index_col='PassengerId')\n","\n","\n","df = pd.concat([titanic_train, titanic_test])"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","    <tr>\n","      <th>PassengerId</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1305</th>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>Spector, Mr. Woolf</td>\n","      <td>male</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>A.5. 3236</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1306</th>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>Oliva y Ocana, Dona. Fermina</td>\n","      <td>female</td>\n","      <td>39.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>PC 17758</td>\n","      <td>108.9000</td>\n","      <td>C105</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>1307</th>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>Saether, Mr. Simon Sivertsen</td>\n","      <td>male</td>\n","      <td>38.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>SOTON/O.Q. 3101262</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1308</th>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>Ware, Mr. Frederick</td>\n","      <td>male</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>359309</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1309</th>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>Peter, Master. Michael J</td>\n","      <td>male</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2668</td>\n","      <td>22.3583</td>\n","      <td>NaN</td>\n","      <td>C</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1309 rows Ã— 11 columns</p>\n","</div>"],"text/plain":["             Survived  Pclass  \\\n","PassengerId                     \n","1                 0.0       3   \n","2                 1.0       1   \n","3                 1.0       3   \n","4                 1.0       1   \n","5                 0.0       3   \n","...               ...     ...   \n","1305              NaN       3   \n","1306              NaN       1   \n","1307              NaN       3   \n","1308              NaN       3   \n","1309              NaN       3   \n","\n","                                                          Name     Sex   Age  \\\n","PassengerId                                                                    \n","1                                      Braund, Mr. Owen Harris    male  22.0   \n","2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n","3                                       Heikkinen, Miss. Laina  female  26.0   \n","4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n","5                                     Allen, Mr. William Henry    male  35.0   \n","...                                                        ...     ...   ...   \n","1305                                        Spector, Mr. Woolf    male   NaN   \n","1306                              Oliva y Ocana, Dona. Fermina  female  39.0   \n","1307                              Saether, Mr. Simon Sivertsen    male  38.5   \n","1308                                       Ware, Mr. Frederick    male   NaN   \n","1309                                  Peter, Master. Michael J    male   NaN   \n","\n","             SibSp  Parch              Ticket      Fare Cabin Embarked  \n","PassengerId                                                             \n","1                1      0           A/5 21171    7.2500   NaN        S  \n","2                1      0            PC 17599   71.2833   C85        C  \n","3                0      0    STON/O2. 3101282    7.9250   NaN        S  \n","4                1      0              113803   53.1000  C123        S  \n","5                0      0              373450    8.0500   NaN        S  \n","...            ...    ...                 ...       ...   ...      ...  \n","1305             0      0           A.5. 3236    8.0500   NaN        S  \n","1306             0      0            PC 17758  108.9000  C105        C  \n","1307             0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n","1308             0      0              359309    8.0500   NaN        S  \n","1309             1      1                2668   22.3583   NaN        C  \n","\n","[1309 rows x 11 columns]"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","metadata":{"id":"K0CJ107MGyja"},"source":["# Indexing and filtering"]},{"cell_type":"markdown","metadata":{"id":"jX-hTMhZGyjb"},"source":["### 1. Fixing age (1 point).\n","\n","There are several known mistakes in the Titanic dataset.\n","\n","Namely, [Julia Florence Siegel](https://www.encyclopedia-titanica.org/titanic-survivor/julia-florence-cavendish.html) (Mrs. Tyrell William Cavendish) is mistakenly marked as being 76 years old (the age she actually died, but many years after Titanic).\n","\n","You must **replace the corresponding age value in the dataframe with her actual age at the time** (25) and return the dataset. Input is **indexed** with `PassengerId` and is a **concatenation of train and test sets**. You must return a copy of the input dataframe, and not perform replacement in the original dataframe. Structure and indexing must be the same as in input."]},{"cell_type":"code","execution_count":37,"metadata":{"ExecuteTime":{"end_time":"2019-12-12T07:45:36.685351Z","start_time":"2019-12-12T07:45:36.675825Z"},"id":"wQYXONuXGyjb"},"outputs":[],"source":["def fix_age(df):\n","    \"\"\"Fix age for Julia Florence Siegel.\"\"\"\n","    df_c = df.copy()\n","    tw_index = df_c.loc[df_c.Name.str.contains('Mrs. Tyrell William')].index\n","    df_c.loc[tw_index, ['Age']] = 25\n","    return df_c"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"0M6SASH8Gyjc"},"outputs":[],"source":["PROBLEM_ID = 1\n","\n","if TEST:\n","    total_grade += solutions.check(STUDENT, PROBLEM_ID, fix_age)"]},{"cell_type":"markdown","metadata":{"id":"7DSLP24ZGyjc"},"source":["### 2. Embarkment port distribution (1 point).\n","\n","You must find the value counts for embarkment port (`Embarked` column) for the passengers, who travelled in 3-d class, were male and between 20 and 30 years old (both inclusive). No need to treat missing values separately.\n","\n","Input is **indexed** with `PassengerId` and is a **concatenation of train and test sets**. You must return **series**, indexed with values from `Embarked`, according to `.value_counts()` method semantics:\n","\n","```\n","S    <number of male passengers in 3-d class, embarked at S, 20<=Age<=30>\n","C    <...>\n","Q    <...>\n","Name: Embarked, dtype: int64\n","```"]},{"cell_type":"code","execution_count":39,"metadata":{"ExecuteTime":{"end_time":"2019-12-12T08:09:19.622389Z","start_time":"2019-12-12T08:09:19.617595Z"},"id":"5XODXvFjGyjd"},"outputs":[],"source":["def embarked_stats(df):\n","    \"\"\"Calculate embarkment port statistics.\"\"\"\n","    return df[(df.Pclass == 3) & (df.Age >=20) & (df.Age <= 30) &(df.Sex == 'male')].Embarked.value_counts()"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/plain":["S    132\n","C     21\n","Q      7\n","Name: Embarked, dtype: int64"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["embarked_stats(df)"]},{"cell_type":"code","execution_count":41,"metadata":{"ExecuteTime":{"end_time":"2019-11-13T23:25:50.106449Z","start_time":"2019-11-13T23:25:50.095086Z"},"id":"j6tsveo3Gyjd"},"outputs":[],"source":["PROBLEM_ID = 2\n","\n","if TEST:\n","    total_grade += solutions.check(STUDENT, PROBLEM_ID, embarked_stats)"]},{"cell_type":"markdown","metadata":{"id":"OD0CRvSxGyje"},"source":["### 3. Fill missing age values (1 point).\n","\n","Some age values are missing in the Titanic dataset. You need to calculate average age over all passengers, and fill missing age values in `Age` column.\n","\n","Input is **indexed** with `PassengerId` and is a **concatenation of train and test sets**. Output must be a **new** dataframe with the same structure, but without missing values in `Age` column."]},{"cell_type":"code","execution_count":42,"metadata":{"ExecuteTime":{"end_time":"2019-11-25T08:26:56.688466Z","start_time":"2019-11-25T08:26:56.684610Z"},"id":"1jbA5q8uGyje"},"outputs":[],"source":["def fix_age(df):\n","    \"\"\"Fix missing age values.\"\"\"\n","    df_c = df.copy()\n","    avg_age = df_c.Age.mean()\n","    df_c['Age'] = df_c.Age.fillna(avg_age)\n","    return df_c\n","    "]},{"cell_type":"code","execution_count":43,"metadata":{"ExecuteTime":{"end_time":"2019-11-25T10:03:45.213116Z","start_time":"2019-11-25T10:03:45.199909Z"},"id":"sPa1XsuSGyje"},"outputs":[],"source":["PROBLEM_ID = 3\n","\n","if TEST:\n","    total_grade += solutions.check(STUDENT, PROBLEM_ID, fix_age)"]},{"cell_type":"markdown","metadata":{"id":"Q2eW8f3QGyjf"},"source":["### 4. Child travelling alone (1 point).\n","\n","You must find a child (`Age<10`) on-board, who was travelling without siblings or parents and find a name of her nursemaid.\n","\n","Input is **indexed** with `PassengerId` and is a **concatenation of train and test sets**. Output must be a **tuple** of two strings, collected from `Name` column, with one being child's name and second being nursemaid's name. It's known, that there's **only one child** like this."]},{"cell_type":"code","execution_count":44,"metadata":{"ExecuteTime":{"end_time":"2019-11-13T23:15:11.348224Z","start_time":"2019-11-13T23:15:11.334569Z"},"id":"ks53WankGyjf"},"outputs":[],"source":["def get_nursemaid(df):\n","    ticket = df[(df.Age < 10) & (df.Parch == 0)].Ticket.item()\n","    nurme_name, child_name  = df[(df.Ticket == ticket) ].Name.to_list()\n","    return (child_name, nurme_name)"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/plain":["('Emanuel, Miss. Virginia Ethel', 'Dowdell, Miss. Elizabeth')"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["get_nursemaid(df)"]},{"cell_type":"code","execution_count":46,"metadata":{"ExecuteTime":{"end_time":"2019-11-13T23:25:50.106449Z","start_time":"2019-11-13T23:25:50.095086Z"},"id":"Y-A2y1WXGyjf"},"outputs":[],"source":["PROBLEM_ID = 4\n","\n","if TEST:\n","    total_grade += solutions.check(STUDENT, PROBLEM_ID, get_nursemaid)"]},{"cell_type":"markdown","metadata":{"id":"9A1HnOo4Gyjf"},"source":["### 5. Port with the most children embarked (1 point).\n","\n","You must find, which port had the largest percentage of children (`Age<10`) embarked, i.e. number of children divided by total number of passengers embarked.\n","\n","Input is **indexed** with `PassengerId` and is a **concatenation of train and test sets**. Output must be a **single string** with port letter."]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[{"data":{"text/plain":["S    0.070022\n","C    0.051852\n","Q    0.032520\n","Name: Embarked, dtype: float64"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["(df[df.Age < 10].Embarked.value_counts() / df.Embarked.value_counts())"]},{"cell_type":"code","execution_count":73,"metadata":{"ExecuteTime":{"end_time":"2019-11-25T08:26:56.688466Z","start_time":"2019-11-25T08:26:56.684610Z"},"id":"MKoxc0aXGyjg"},"outputs":[],"source":["def get_port(df):\n","    \"\"\"Get port with the most children embarked.\"\"\"\n","    s = (df[df.Age < 10].Embarked.value_counts() / df.Embarked.value_counts())\n","    return s.index[0]"]},{"cell_type":"code","execution_count":160,"metadata":{"ExecuteTime":{"end_time":"2019-11-25T08:27:11.838257Z","start_time":"2019-11-25T08:27:11.720830Z"},"id":"9-Jr8SSuGyjg"},"outputs":[],"source":["PROBLEM_ID = 5\n","\n","if TEST:\n","    total_grade += solutions.check(STUDENT, PROBLEM_ID, get_port)"]},{"cell_type":"markdown","metadata":{"id":"l6UrEuFFGyjg"},"source":["### 6. Passengers per ticket (2 points).\n","\n","Calculate average and maximum number of passengers per ticket.\n","\n","Input is **indexed** with `PassengerId` and is a **concatenation of train and test sets**. Output must be a **tuple** of two values - average and maximum number of passengers per ticket."]},{"cell_type":"code","execution_count":161,"metadata":{},"outputs":[{"data":{"text/plain":["11"]},"execution_count":161,"metadata":{},"output_type":"execute_result"}],"source":["df.groupby('Ticket')['Embarked'].value_counts().mean()\n","df.groupby('Ticket')['Embarked'].value_counts().max()\n","# df.groupby('Ticket')['Embarked'].value_counts()"]},{"cell_type":"code","execution_count":162,"metadata":{},"outputs":[{"data":{"text/plain":["Ticket       Embarked\n","110152       S           3\n","110413       S           3\n","110465       S           2\n","110469       S           1\n","110489       S           1\n","                        ..\n","W./C. 6608   S           5\n","W./C. 6609   S           1\n","W.E.P. 5734  S           2\n","W/C 14208    S           1\n","WE/P 5735    S           2\n","Name: Embarked, Length: 930, dtype: int64"]},"execution_count":162,"metadata":{},"output_type":"execute_result"}],"source":["df.groupby('Ticket')['Embarked'].value_counts()"]},{"cell_type":"code","execution_count":163,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","    <tr>\n","      <th>PassengerId</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>263</th>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>Taussig, Mr. Emil</td>\n","      <td>male</td>\n","      <td>52.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>110413</td>\n","      <td>79.65</td>\n","      <td>E67</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>559</th>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>Taussig, Mrs. Emil (Tillie Mandelbaum)</td>\n","      <td>female</td>\n","      <td>39.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>110413</td>\n","      <td>79.65</td>\n","      <td>E67</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>586</th>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>Taussig, Miss. Ruth</td>\n","      <td>female</td>\n","      <td>18.0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>110413</td>\n","      <td>79.65</td>\n","      <td>E68</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             Survived  Pclass                                    Name     Sex  \\\n","PassengerId                                                                     \n","263               0.0       1                       Taussig, Mr. Emil    male   \n","559               1.0       1  Taussig, Mrs. Emil (Tillie Mandelbaum)  female   \n","586               1.0       1                     Taussig, Miss. Ruth  female   \n","\n","              Age  SibSp  Parch  Ticket   Fare Cabin Embarked  \n","PassengerId                                                    \n","263          52.0      1      1  110413  79.65   E67        S  \n","559          39.0      1      1  110413  79.65   E67        S  \n","586          18.0      0      2  110413  79.65   E68        S  "]},"execution_count":163,"metadata":{},"output_type":"execute_result"}],"source":["df[df.Ticket == '110413']"]},{"cell_type":"code","execution_count":164,"metadata":{},"outputs":[{"data":{"text/plain":["11"]},"execution_count":164,"metadata":{},"output_type":"execute_result"}],"source":["ticket_gb = df.groupby('Ticket')['Embarked']\n","\n","ticket_gb.value_counts().max()"]},{"cell_type":"code","execution_count":165,"metadata":{"ExecuteTime":{"end_time":"2019-11-25T08:26:56.688466Z","start_time":"2019-11-25T08:26:56.684610Z"},"id":"BeejKFJkGyjg"},"outputs":[],"source":["def get_ticket_stats(df):\n","    \"\"\"Calculate passenger per ticket statistics.\"\"\"\n","    ticket_gb_vc = df.groupby('Ticket')['Embarked'].value_counts()\n","    return (ticket_gb_vc.mean(), ticket_gb_vc.max())"]},{"cell_type":"code","execution_count":166,"metadata":{"ExecuteTime":{"end_time":"2019-11-25T08:27:11.838257Z","start_time":"2019-11-25T08:27:11.720830Z"},"id":"BJhXFyymGyjg"},"outputs":[],"source":["PROBLEM_ID = 6\n","\n","if TEST:\n","    total_grade += solutions.check(STUDENT, PROBLEM_ID, get_ticket_stats)"]},{"cell_type":"markdown","metadata":{"id":"i-mw9DIVGyjh"},"source":["### 7. Fare per passenger (3 points).\n","\n","For each individual ticket, you must calculate **fare per person for that ticket**, and then calculate averages for each class. Note, that you will need to apply `groupby` and you may consider using `.first()` of resulting `DataFrameGroupBy`. Also, caferully consider, in which order calculations are performed.\n","\n","Input is **indexed** with `PassengerId` and is a **concatenation of train and test sets**. Output must be `pd.Series` with three elements, indexed by class:\n","\n","```\n","1    <average per person fare in class 1>\n","2    <...>\n","3    <...>\n","Name: Pclass, dtype: float64\n","```"]},{"cell_type":"code","execution_count":168,"metadata":{},"outputs":[{"data":{"text/plain":["Ticket\n","110152         86.500\n","110413         79.650\n","110465         52.000\n","110469         26.000\n","110489         26.550\n","                ...  \n","W./C. 6608     34.375\n","W./C. 6609      7.550\n","W.E.P. 5734    61.175\n","W/C 14208      10.500\n","WE/P 5735      71.000\n","Name: Fare, Length: 929, dtype: float64"]},"execution_count":168,"metadata":{},"output_type":"execute_result"}],"source":["df.groupby(['Ticket']).Fare.mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-25T08:26:56.688466Z","start_time":"2019-11-25T08:26:56.684610Z"},"id":"IkPBSGhQGyjh"},"outputs":[],"source":["def get_fare_per_pass(df):\n","    \"\"\"Calculate fare per passenger for different classes.\"\"\"\n","    pass"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-25T08:27:11.838257Z","start_time":"2019-11-25T08:27:11.720830Z"},"id":"wQrz-9RKGyjh"},"outputs":[],"source":["PROBLEM_ID = 7\n","\n","if TEST:\n","    total_grade += solutions.check(STUDENT, PROBLEM_ID, get_fare_per_pass)"]},{"cell_type":"markdown","metadata":{"id":"Ga60QNRGGyjh"},"source":["### 8. Fill missing age values (3 points).\n","\n","In problem 3 you filled missing age values with global average over all passengers. Now, you need to fill them **according to class and sex**. For example, for a female passenger from 2d class, missing age value must be filled with average age of females in 2d class.\n","\n","In this problem, you may need joins and `.apply()`, although there are several ways to get the same result.\n","\n","Input is **indexed** with `PassengerId` and is a **concatenation of train and test sets**. Output must be a **new** dataframe with the same structure as input, but without missing values in `Age` column."]},{"cell_type":"code","execution_count":130,"metadata":{"ExecuteTime":{"end_time":"2019-11-25T08:26:56.688466Z","start_time":"2019-11-25T08:26:56.684610Z"},"id":"GNb5uS3YGyjh"},"outputs":[],"source":["def fix_age_groupped(df):\n","    \"\"\"Fill missing age values.\"\"\"\n","    df_c = df.copy()\n","    gb_mean = df_c.groupby([df_c.Pclass.name, df_c.Sex.name])['Age'].mean()\n","\n","\n","    for c in [1,2,3]:\n","        for s in ['female','male']:\n","            idx = df_c[(df_c.Pclass == c) & (df_c.Sex == s) & (df_c['Age'].isna())].index\n","            df_c.loc[idx, ['Age']] = gb_mean.loc[c,s]\n","\n","    return df_c"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fix_age_groupped"]},{"cell_type":"code","execution_count":138,"metadata":{},"outputs":[{"data":{"text/plain":["Age    25.962264\n","dtype: float64"]},"execution_count":138,"metadata":{},"output_type":"execute_result"}],"source":["df.loc[(df.Pclass == 3) & (df.Sex == 'male'),['Age']].mean()"]},{"cell_type":"code","execution_count":139,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","    <tr>\n","      <th>PassengerId</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1305</th>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>Spector, Mr. Woolf</td>\n","      <td>male</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>A.5. 3236</td>\n","      <td>8.05</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             Survived  Pclass                Name   Sex  Age  SibSp  Parch  \\\n","PassengerId                                                                  \n","1305              NaN       3  Spector, Mr. Woolf  male  NaN      0      0   \n","\n","                Ticket  Fare Cabin Embarked  \n","PassengerId                                  \n","1305         A.5. 3236  8.05   NaN        S  "]},"execution_count":139,"metadata":{},"output_type":"execute_result"}],"source":["df[df.Name == 'Spector, Mr. Woolf']"]},{"cell_type":"code","execution_count":137,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","    <tr>\n","      <th>PassengerId</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1305</th>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>Spector, Mr. Woolf</td>\n","      <td>male</td>\n","      <td>25.962264</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>A.5. 3236</td>\n","      <td>8.05</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             Survived  Pclass                Name   Sex        Age  SibSp  \\\n","PassengerId                                                                 \n","1305              NaN       3  Spector, Mr. Woolf  male  25.962264      0   \n","\n","             Parch     Ticket  Fare Cabin Embarked  \n","PassengerId                                         \n","1305             0  A.5. 3236  8.05   NaN        S  "]},"execution_count":137,"metadata":{},"output_type":"execute_result"}],"source":["d = fix_age_groupped(df)\n","d[d.Name == 'Spector, Mr. Woolf'] # expect to see 25.962\n"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-25T08:27:11.838257Z","start_time":"2019-11-25T08:27:11.720830Z"},"id":"RLU1W4uuGyjh"},"outputs":[],"source":["PROBLEM_ID = 8\n","\n","if TEST:\n","    total_grade += solutions.check(STUDENT, PROBLEM_ID, fix_age_groupped)"]},{"cell_type":"markdown","metadata":{"id":"tGE3ggVqGyji"},"source":["### 9. Finding couples (3 points).\n","\n","Based on the code from Lecture 5, build a dataframe of couples. Filter it by survival status: select those couples, in which only one of spouses survived or none of two. Built survival statistics by class, i.e. ratio of the number couples with partial survival or couples which died together, divided by total number of couples in class. If the survival status of one or both of spouses is not known, it must be considered as `0`.\n","\n","Input is **indexed** with `PassengerId` and is a **concatenation of train and test sets**. Output must be `Series` with three elements indexed by values from `Pclass` column (see P7 as a reference)."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-25T08:26:56.688466Z","start_time":"2019-11-25T08:26:56.684610Z"},"id":"T8Cclj30Gyji"},"outputs":[],"source":["def find_couples(df):\n","    \"\"\"Fill missing age values.\"\"\"\n","    pass"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-25T08:27:11.838257Z","start_time":"2019-11-25T08:27:11.720830Z"},"id":"l-xTDP21Gyji"},"outputs":[],"source":["PROBLEM_ID = 9\n","\n","if TEST:\n","    total_grade += solutions.check(STUDENT, PROBLEM_ID, find_couples)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"38VBoob1Gyji"},"outputs":[],"source":["if TEST:\n","    print(f\"{STUDENT}: {int(100 * total_grade / MAX_POINTS)}\")"]}],"metadata":{"@webio":{"lastCommId":null,"lastKernelId":null},"celltoolbar":"Tags","colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.9.13 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"97bf5cac092693491f9f0c093044444828bd281c57f8a7f0d4a6df9d6c416292"}}},"nbformat":4,"nbformat_minor":0}
