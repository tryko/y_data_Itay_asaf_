{"cells":[{"cell_type":"markdown","metadata":{"id":"9zC2e0uaOz2F"},"source":["# Intro\n","\n","Pandas has first-class support for datetime types, including flexible indexing, vectorized operations, `groupby` operations and joins. This makes EDA on time series data with Pandas very convenient and productive."]},{"cell_type":"markdown","metadata":{},"source":["# NOTEBOOK WON'T WORK, CSV FILE IS TO BIG TO UPLOAD TO GIT"]},{"cell_type":"code","execution_count":1,"metadata":{"ExecuteTime":{"end_time":"2019-12-10T03:08:15.291893Z","start_time":"2019-12-10T03:08:14.345395Z"},"id":"L5b9Jm7SOz2J"},"outputs":[{"name":"stdout","output_type":"stream","text":["Populating the interactive namespace from numpy and matplotlib\n"]}],"source":["%pylab inline\n","plt.style.use('bmh')\n","\n","import pathlib\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","sns.set()"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"UjGkMTpWOz2K"},"outputs":[],"source":["DATA_DIR = pathlib.Path(\"./\")"]},{"cell_type":"markdown","metadata":{"id":"-D0JqDz0Oz2L"},"source":["# Loading data\n","\n","The dataset we'll use to explore time series functionality in Pandas is [1.6 million UK traffic accidents](https://www.kaggle.com/daveianhickey/2000-16-traffic-flow-england-scotland-wales). The full dataset contains years 2005-2007, but note that in the Exam we only use 2005."]},{"cell_type":"code","execution_count":4,"metadata":{"ExecuteTime":{"end_time":"2019-12-10T03:08:19.413003Z","start_time":"2019-12-10T03:08:16.072626Z"},"id":"Os79DDg_Oz2L"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\itay8\\AppData\\Local\\Temp\\ipykernel_20256\\531325847.py:1: DtypeWarning: Columns (31) have mixed types. Specify dtype option on import or set low_memory=False.\n","  d = pd.read_csv(DATA_DIR.joinpath('accidents_2005_to_2007.csv.zip'))\n"]}],"source":["d = pd.read_csv(DATA_DIR.joinpath('accidents_2005_to_2007.csv.zip'))"]},{"cell_type":"markdown","metadata":{"id":"MS4M5ONTOz2M"},"source":["Dataset is quite large. Let's explore it's per-column breakdown:"]},{"cell_type":"code","execution_count":5,"metadata":{"ExecuteTime":{"end_time":"2019-11-29T10:55:44.277439Z","start_time":"2019-11-29T10:55:35.345736Z"},"id":"2-kckpHyOz2M"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 570011 entries, 0 to 570010\n","Data columns (total 33 columns):\n"," #   Column                                       Non-Null Count   Dtype  \n","---  ------                                       --------------   -----  \n"," 0   Accident_Index                               570011 non-null  object \n"," 1   Location_Easting_OSGR                        569910 non-null  float64\n"," 2   Location_Northing_OSGR                       569910 non-null  float64\n"," 3   Longitude                                    569910 non-null  float64\n"," 4   Latitude                                     569910 non-null  float64\n"," 5   Police_Force                                 570011 non-null  int64  \n"," 6   Accident_Severity                            570011 non-null  int64  \n"," 7   Number_of_Vehicles                           570011 non-null  int64  \n"," 8   Number_of_Casualties                         570011 non-null  int64  \n"," 9   Date                                         570011 non-null  object \n"," 10  Day_of_Week                                  570011 non-null  int64  \n"," 11  Time                                         569944 non-null  object \n"," 12  Local_Authority_(District)                   570011 non-null  int64  \n"," 13  Local_Authority_(Highway)                    570011 non-null  object \n"," 14  1st_Road_Class                               570011 non-null  int64  \n"," 15  1st_Road_Number                              570011 non-null  int64  \n"," 16  Road_Type                                    570011 non-null  object \n"," 17  Speed_limit                                  570011 non-null  int64  \n"," 18  Junction_Detail                              0 non-null       float64\n"," 19  Junction_Control                             333066 non-null  object \n"," 20  2nd_Road_Class                               570011 non-null  int64  \n"," 21  2nd_Road_Number                              570011 non-null  int64  \n"," 22  Pedestrian_Crossing-Human_Control            569994 non-null  object \n"," 23  Pedestrian_Crossing-Physical_Facilities      569977 non-null  object \n"," 24  Light_Conditions                             570011 non-null  object \n"," 25  Weather_Conditions                           569991 non-null  object \n"," 26  Road_Surface_Conditions                      569349 non-null  object \n"," 27  Special_Conditions_at_Site                   570000 non-null  object \n"," 28  Carriageway_Hazards                          569988 non-null  object \n"," 29  Urban_or_Rural_Area                          570011 non-null  int64  \n"," 30  Did_Police_Officer_Attend_Scene_of_Accident  567636 non-null  object \n"," 31  LSOA_of_Accident_Location                    522500 non-null  object \n"," 32  Year                                         570011 non-null  int64  \n","dtypes: float64(5), int64(13), object(15)\n","memory usage: 645.8 MB\n"]}],"source":["d.info(memory_usage=\"deep\")"]},{"cell_type":"markdown","metadata":{"id":"DyPVE2NoOz2N"},"source":["As we can see, it has date and time in separate columns, and we need to combine it into full datetime:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-29T10:56:35.191082Z","start_time":"2019-11-29T10:56:35.182679Z"},"id":"Mg9yLJ_DOz2N"},"outputs":[],"source":["d.Date.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vEeYccW9Oz2O"},"outputs":[],"source":["d.Time.head()"]},{"cell_type":"markdown","metadata":{"id":"KNLU0UYFOz2O"},"source":["Let's explore if we have any missing dates or times:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BsnqaNi-Oz2P"},"outputs":[],"source":["d[d.Date.isnull()]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BbODbks7Oz2P"},"outputs":[],"source":["d[d.Time.isnull()]"]},{"cell_type":"markdown","metadata":{"id":"JxmpajqbOz2P"},"source":["We may note the following:\n","    \n","- date and time are provided as strings,\n","- we have slashes in dates, and this can be parsed ambiguously,\n","- some times are missing.\n","\n","Hence, our strategy is the following:\n","\n","- concatenate date and time using string vectorized operations,\n","- set placeholder for missing times to be `00:00`,\n","- parse resulting (**string**) datetime with explicit `dayfirst=True`."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-12-10T03:59:06.660109Z","start_time":"2019-12-10T03:59:06.053974Z"},"id":"1igIizT9Oz2Q"},"outputs":[],"source":["d.loc[:, 'dt'] = d.Date.str.cat(d.Time, sep=' ', na_rep='00:00')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eJ9EQOdqOz2Q"},"outputs":[],"source":["d.dt"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-12-10T04:00:17.802037Z","start_time":"2019-12-10T03:59:07.486205Z"},"id":"7MSnUUhYOz2Q"},"outputs":[],"source":["d.loc[:, 'date_time'] = pd.to_datetime(d.dt, dayfirst=True)"]},{"cell_type":"markdown","metadata":{"id":"WzWb71_0Oz2R"},"source":["We now have `date_time` column of type `datetime64[ns]`:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-29T11:01:46.697903Z","start_time":"2019-11-29T11:01:46.196623Z"},"id":"IzwSF75pOz2R"},"outputs":[],"source":["d.info()  # Note the difference without `memory_usage=\"deep\"`"]},{"cell_type":"markdown","metadata":{"id":"gvs0V-7iOz2R"},"source":["Let's filter some columns we do not need:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-29T11:02:12.865694Z","start_time":"2019-11-29T11:02:12.855369Z"},"id":"JP4qh1PFOz2S"},"outputs":[],"source":["d.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-12-10T04:00:21.633529Z","start_time":"2019-12-10T04:00:21.629740Z"},"id":"zWtvhJeTOz2S"},"outputs":[],"source":["COLS = ['Accident_Index', 'Longitude', 'Latitude',\n","        'Accident_Severity', 'Number_of_Vehicles',\n","        'Number_of_Casualties', 'Weather_Conditions',\n","        'Day_of_Week', 'Road_Surface_Conditions',\n","        'Special_Conditions_at_Site', 'Urban_or_Rural_Area',\n","        'Carriageway_Hazards', 'date_time']"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-12-10T04:00:22.160014Z","start_time":"2019-12-10T04:00:22.036386Z"},"id":"MHCFRrIgOz2S"},"outputs":[],"source":["d.drop([c for c in d.columns if c not in COLS], axis=1, inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"5TbP6WCtOz2S"},"source":["Pandas has a dedicated set of index types for datetime indexes:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-12-10T04:01:30.916550Z","start_time":"2019-12-10T04:01:30.910140Z"},"id":"NBY2gMqbOz2T"},"outputs":[],"source":["d.set_index('date_time', inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-29T11:03:46.901039Z","start_time":"2019-11-29T11:03:46.871496Z"},"id":"w-oJZXTBOz2T"},"outputs":[],"source":["d.index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pVgJjUn2Oz2T"},"outputs":[],"source":["d.head()"]},{"cell_type":"markdown","metadata":{"id":"h1ypzlUeOz2T"},"source":["# `DatetimeIndex` in details\n","\n","`DatetimeIndex` is special in many ways. It allows for much more flexible indexing compared to usual indexes. First of all, you can use strings, not just actual index labels. To leverage this, we first sort the index:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZwaqRp1wOz2U"},"outputs":[],"source":["d.sort_index(inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"8cTOWGN3Oz2U"},"source":["We can now use strings to index the dataframe (indexing non-monotonic `DatetimeIndex` with strings is not a very good idea):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xhjdV-eHOz2U"},"outputs":[],"source":["d[\"2006-02-12 20\":\"2006-03\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m7G2b0x-Oz2U"},"outputs":[],"source":["d[\"2006\":]"]},{"cell_type":"markdown","metadata":{"id":"PGfsO3DHOz2U"},"source":["Note, how Pandas allows for partial datetime string specification. Of course, this way of indexing can be combined with column index:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q598sqaoOz2U"},"outputs":[],"source":["d.loc[\"2005\", \"Accident_Severity\"]"]},{"cell_type":"markdown","metadata":{"id":"GMvXCtshOz2V"},"source":["We will now create a dataframe used in Problem 6 of the exam:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8eO4xpioOz2V"},"outputs":[],"source":["d.loc[\"2005\", \"Accident_Severity\"].to_csv(DATA_DIR.joinpath(\"accidents_2005.csv\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AxJnhP4YOz2V"},"outputs":[],"source":["accidents_2005 = pd.read_csv(DATA_DIR.joinpath(\"accidents_2005.csv\"),\n","                             parse_dates=[\"date_time\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jaWYBmJoOz2V"},"outputs":[],"source":["accidents_2005.head()"]},{"cell_type":"markdown","metadata":{"id":"iueGjVAAOz2V"},"source":["Note, that it's not indexed, and that's exactly the way it's passed to the solution function."]},{"cell_type":"markdown","metadata":{"id":"keiGgTq-Oz2W"},"source":["# Resampling time series\n","\n","Time series in Pandas can be easily resampled to any frequency:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"unybHS4MOz2W"},"outputs":[],"source":["d.resample('D')"]},{"cell_type":"markdown","metadata":{"id":"mtdouisWOz2W"},"source":["Similar to `groupby`, `resample` doesn't perform any operations on it's own, but just calculates which rows go to which (datetime) bin. We need to further apply some aggregation operation. For example, we may calculate number of accidents per day:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-29T11:05:28.462633Z","start_time":"2019-11-29T11:05:27.690959Z"},"id":"qrcP5wMmOz2W"},"outputs":[],"source":["daily = d.resample('D').size()\n","daily"]},{"cell_type":"markdown","metadata":{"id":"ZeHQROY3Oz2W"},"source":["`daily` has `DatetimeIndex` as well and has `freq` specified (as it was constructed to have one):"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-29T11:08:18.144611Z","start_time":"2019-11-29T11:08:18.129978Z"},"id":"l4mxqJuMOz2W"},"outputs":[],"source":["daily.index"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-29T11:08:38.088035Z","start_time":"2019-11-29T11:08:38.081855Z"},"id":"UzlsFIYBOz2X"},"outputs":[],"source":["daily.index.is_monotonic, daily.index.is_unique"]},{"cell_type":"markdown","metadata":{"id":"hY7GLM-COz2X"},"source":["Pandas also exposes plotting functionality to datetime-indexed dataframes. To illustrate this, let's plot daily and weekly average number of accidents:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-29T11:10:30.721510Z","start_time":"2019-11-29T11:10:28.894634Z"},"id":"faT76W5kOz2X"},"outputs":[],"source":["# Just a hint: you can set image resolution in dpi\n","plt.figure(figsize=(8,3), dpi=150)  \n","\n","daily.plot(ax=plt.gca(), linewidth=0.5)\n","\n","(d.resample('W').size()/7.).plot(ax=plt.gca(),\n","                                 linewidth=1,\n","                                 color='firebrick')\n","\n","plt.ylabel('average daily accidents')\n","plt.xlabel('week');"]},{"cell_type":"markdown","metadata":{"id":"5n9BhgDMOz2X"},"source":["In EDA terms, we just gained our first insight: accidents are strongly seasonal (with non-trivial seasonal struture and high dependence on holidays).\n","\n","Similarly, we can plot daily and weekly average number of vehicles involved:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-29T11:16:09.457767Z","start_time":"2019-11-29T11:16:07.126195Z"},"id":"_TwxTzx7Oz2X"},"outputs":[],"source":["plt.figure(figsize=(12,5), dpi=150)\n","\n","d.resample('D').Number_of_Vehicles.mean().plot(ax=plt.gca())\n","d.resample('W').Number_of_Vehicles.mean().plot(ax=plt.gca(), color='firebrick')\n","\n","plt.ylabel('vehicles involved')\n","plt.xlabel('week');"]},{"cell_type":"markdown","metadata":{"id":"FmuF9asdOz2Y"},"source":["Instead of `resample`, we can use `pd.Grouper`. It's not really useful as a replacement of `resample`, but is very handy in compound grouping keys."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-12-10T04:04:18.632329Z","start_time":"2019-12-10T04:04:17.912497Z"},"id":"ObL4IUr1Oz2Y"},"outputs":[],"source":["d.groupby(pd.Grouper(freq='D'))[\"Number_of_Casualties\"].mean()"]},{"cell_type":"markdown","metadata":{"id":"EP9Ur5RWOz2Y"},"source":["Now, let's try to extract the accidents, which have more casualties, than average number of casualties on that day. And now Pandas datetime magic comes into play:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a9olWrsZOz2Y"},"outputs":[],"source":["daily_casualties = (d\n","                    .groupby(pd.Grouper(freq='D'))[\"Number_of_Casualties\"]\n","                    .mean())\n","\n","df = d.merge(daily_casualties,\n","             left_on=d.index.floor(\"1D\"),\n","             right_index=True,\n","             suffixes=(\"\", \"_daily\"))"]},{"cell_type":"markdown","metadata":{"id":"x69reqjcOz2Y"},"source":["Note that Pandas keeps the calculated key it used for merging as `key_0`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GZc9PakMOz2Z"},"outputs":[],"source":["df.head()"]},{"cell_type":"markdown","metadata":{"id":"-eDWDwYTOz2Z"},"source":["We do not need it at the moment, so we'll drop it:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6sxXoDPeOz2Z"},"outputs":[],"source":["df.drop(\"key_0\", axis=1, inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"u7rt3naAOz2Z"},"source":["We can now calculate how extreme each accident is compared to daily averages:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y2srSNziOz2Z"},"outputs":[],"source":["df[\"delta\"] = df[\"Number_of_Casualties\"] - df[\"Number_of_Casualties_daily\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-12-10T04:23:37.054620Z","start_time":"2019-12-10T04:23:36.813830Z"},"id":"N19q3YcAOz2Z"},"outputs":[],"source":["df.loc[\"2005\"].sort_values(by=\"delta\", ascending=False)"]},{"cell_type":"markdown","metadata":{"id":"oWmbuV-BOz2Z"},"source":["Let's explore the most extreme one:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-12-10T04:15:41.114578Z","start_time":"2019-12-10T04:15:41.024410Z"},"id":"9CjlH0IlOz2a"},"outputs":[],"source":["d[d.Accident_Index==\"200597EC70504\"]"]},{"cell_type":"markdown","metadata":{"id":"jyWHCO7TOz2a"},"source":["You may want to further investigate this case (with Google of course)."]},{"cell_type":"markdown","metadata":{"id":"A4ZdcMa5Oz2a"},"source":["Let's get back to `pd.Grouper` and compound keys. We can flexibly combine grouper on datetime index with usual column. Let's calculate now many accidents we have per area type each day:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_skMvnZhOz2a"},"outputs":[],"source":["d.groupby([pd.Grouper(freq='1M'), 'Urban_or_Rural_Area']).size()"]},{"cell_type":"markdown","metadata":{"id":"2p86Vb0HOz2a"},"source":["Now we can plot this as a stacked bar plot:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-29T11:21:14.514994Z","start_time":"2019-11-29T11:21:12.102644Z"},"id":"iejc70SKOz2a"},"outputs":[],"source":["plt.figure(figsize=(12,6))\n","\n","(d.groupby([pd.Grouper(freq='1M'), 'Urban_or_Rural_Area'])\n"," .size()\n"," .unstack()\n"," .plot(alpha=0.6, linewidth=2, ax=plt.gca(), kind='bar', stacked=True));"]},{"cell_type":"markdown","metadata":{"id":"nEOFRcJdOz2a"},"source":["We can do the same with accident severity:"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-29T11:23:14.585941Z","start_time":"2019-11-29T11:23:12.156308Z"},"id":"-vEWwtB5Oz2a"},"outputs":[],"source":["plt.figure(figsize=(12,6))\n","\n","(d.groupby([pd.Grouper(freq='1M'), 'Accident_Severity'])\n"," .size()\n"," .unstack()\n"," .plot(alpha=0.6, linewidth=2, ax=plt.gca(), kind='bar', stacked=True));"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.9.13 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"97bf5cac092693491f9f0c093044444828bd281c57f8a7f0d4a6df9d6c416292"}}},"nbformat":4,"nbformat_minor":0}
