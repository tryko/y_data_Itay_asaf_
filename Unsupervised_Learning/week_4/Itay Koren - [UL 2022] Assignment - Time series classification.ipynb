{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you'll have to explore and classify time series. The dataset is [FordA](http://www.timeseriesclassification.com/description.php?Dataset=FordA), which is a set of recordings of engine noise under typical conditions and you need to classify if certain condition exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T11:46:03.122781Z",
     "start_time": "2023-01-03T11:46:02.409389Z"
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plt.style.use(\"bmh\")\n",
    "plt.rcParams[\"figure.figsize\"] = (6,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T11:47:43.968230Z",
     "start_time": "2023-01-03T11:47:43.402197Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting improts\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:18:55.631814Z",
     "start_time": "2023-01-03T12:18:55.623824Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generic imports\n",
    "import pathlib\n",
    "\n",
    "# DS imports\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T11:47:57.754500Z",
     "start_time": "2023-01-03T11:47:57.747438Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = pathlib.Path(\"data/\")\n",
    "DATASET = \"FordA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data files are stored in tabular format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:19:04.840957Z",
     "start_time": "2023-01-03T12:19:04.703589Z"
    }
   },
   "outputs": [],
   "source": [
    "!head -n 2 data/FordA/FordA_TRAIN.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:19:11.947465Z",
     "start_time": "2023-01-03T12:19:11.460753Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_DIR.joinpath(DATASET, f\"{DATASET}_TRAIN.txt\"),\n",
    "                    header=None,\n",
    "                    sep=\"\\s+\",\n",
    "                    skipinitialspace=True)\n",
    "test = pd.read_csv(DATA_DIR.joinpath(DATASET, f\"{DATASET}_TEST.txt\"),\n",
    "                   header=None,\n",
    "                   sep=\"\\s+\",\n",
    "                   skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:19:11.965050Z",
     "start_time": "2023-01-03T12:19:11.948932Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, each row represents a single measurement, with column `0` being class label, and columns `1-501` being measured values. Let's check missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:19:11.990339Z",
     "start_time": "2023-01-03T12:19:11.983203Z"
    }
   },
   "outputs": [],
   "source": [
    "train.notnull().sum(axis=1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:04:29.176293Z",
     "start_time": "2023-01-03T12:04:29.160729Z"
    }
   },
   "outputs": [],
   "source": [
    "test.notnull().sum(axis=1).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change column names to something meaningful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:27:24.058588Z",
     "start_time": "2023-01-03T12:27:24.044757Z"
    }
   },
   "outputs": [],
   "source": [
    "train.rename({0: \"label\"}, axis=1, inplace=True)\n",
    "test.rename({0: \"label\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:27:24.176464Z",
     "start_time": "2023-01-03T12:27:24.171004Z"
    }
   },
   "outputs": [],
   "source": [
    "train.rename({cl: f\"val_{cl}\" for cl in range(1, 501)}, axis=1, inplace=True)\n",
    "test.rename({cl: f\"val_{cl}\" for cl in range(1, 501)}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now select data values by filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:27:26.252486Z",
     "start_time": "2023-01-03T12:27:26.218126Z"
    }
   },
   "outputs": [],
   "source": [
    "train.filter(like=\"val_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is almost balanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:25:37.528221Z",
     "start_time": "2023-01-03T12:25:37.512084Z"
    }
   },
   "outputs": [],
   "source": [
    "train.iloc[:, 0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:25:40.743052Z",
     "start_time": "2023-01-03T12:25:40.738932Z"
    }
   },
   "outputs": [],
   "source": [
    "test.iloc[:, 0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: explore time series\n",
    "\n",
    "In this task you need to plot data samples with class label designation. Consider 10 or 20 random samples, and create a `2 x 5` or `4 x 5` plot, with eash subplot being the data records (i. e. `train.filter(like=\"val_\").iloc[<sample_idx>]`), subtitles displaying sample index and class label. You can use color as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:24:00.667300Z",
     "start_time": "2023-01-03T12:24:00.657681Z"
    }
   },
   "outputs": [],
   "source": [
    "N_SAMPLES = 20\n",
    "N_COLS = 5\n",
    "N_ROWS = 20 // N_COLS\n",
    "\n",
    "samples = train.sample(N_SAMPLES, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:28:54.025672Z",
     "start_time": "2023-01-03T12:28:52.515510Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3 * N_ROWS, 3 * N_COLS))\n",
    "\n",
    "for si, (sidx, sample) in enumerate(samples.iterrows()):\n",
    "    # plot one sample here on a corresponding subplot\n",
    "    pass\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: explore statistics\n",
    "\n",
    "In this task you need to plot simple statistics for each class, i. e. calculate `mean`, `median`, `std` and other statistics (of your choice) for each row and then visualize them in such a way, that one can figure out if a distribution of a given statistics differs between class `1` and `-1`.\n",
    "\n",
    "**Hint:** you can consider [violin plots](https://seaborn.pydata.org/examples/grouped_violinplots.html) or [scatter plot matrix](https://seaborn.pydata.org/examples/scatterplot_matrix.html) helpful.\n",
    "\n",
    "## Example: median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:27:29.273435Z",
     "start_time": "2023-01-03T12:27:29.070234Z"
    }
   },
   "outputs": [],
   "source": [
    "train[\"data_median\"] = train.filter(like=\"val_\").median(axis=1)\n",
    "test[\"data_median\"] = test.filter(like=\"val_\").median(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:27:03.603702Z",
     "start_time": "2023-01-03T12:27:03.600474Z"
    }
   },
   "source": [
    "The simplest visualization possible (you need to create smth more elaborated for other features altogether):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:29:13.120348Z",
     "start_time": "2023-01-03T12:29:12.962214Z"
    }
   },
   "outputs": [],
   "source": [
    "train.loc[train[\"label\"]==1, \"data_median\"].plot(kind=\"hist\", range=(-0.2, 0.2), label=\"class 1\")\n",
    "train.loc[train[\"label\"]==-1, \"data_median\"].plot(kind=\"hist\", range=(-0.2, 0.2), alpha=0.6, label=\"class -1\")\n",
    "\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel(\"data median\")\n",
    "plt.ylabel(\"# samples\")\n",
    "plt.title(\"Distributions of median data values\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** we can easily check if median is a good feature with ROC curve and score (as they do not rely on any specific normalization of the \"predicted\" probabilities). Think on why we're using `-data_median`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:33:23.487068Z",
     "start_time": "2023-01-03T12:33:23.475216Z"
    }
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thr = roc_curve(train[\"label\"], -train[\"data_median\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:34:28.140532Z",
     "start_time": "2023-01-03T12:34:28.031187Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], \"--\", c=\"k\", linewidth=1)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC curve for data median\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, median contains *some* information (i. e. looking at median values is better than random classifier), but cannot serve as a *single* feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:39:55.636494Z",
     "start_time": "2023-01-03T12:39:55.630340Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot other statistics here - mean, std, skew, max, min, some quantiles\n",
    "# consider calculating ROC AUC for each feature to perform a preliminary filtering of irrelevant features\n",
    "# beware of NaNs - some statistics may be broken for some rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: explore advanced features\n",
    "\n",
    "In this task you need to calculate and analyze other time series features. looking on the data sample, think on which features in time/frequency domains may be useful for a classification of the dataset.\n",
    "\n",
    "**Hint:** try various features from [`tsfresh`](https://tsfresh.readthedocs.io/en/latest/text/list_of_features.html).\n",
    "\n",
    "## Example: 0-crossings\n",
    "\n",
    "For this features we'll not use `tsfresh`, and will do some ninja stuff in Pandas itself:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** mask on `> 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:44:19.538454Z",
     "start_time": "2023-01-03T12:44:19.500363Z"
    }
   },
   "outputs": [],
   "source": [
    "mask = (train.filter(like=\"val_\") > 0).astype(int)\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** calc `diff` to get crossings (from `< 0` to `> 0`, or other way around)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:44:32.446896Z",
     "start_time": "2023-01-03T12:44:32.423764Z"
    }
   },
   "outputs": [],
   "source": [
    "mask.diff(axis=1) == 1  # crossing from -0 to +0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:44:40.286502Z",
     "start_time": "2023-01-03T12:44:40.239720Z"
    }
   },
   "outputs": [],
   "source": [
    "mask.diff(axis=1) == -1  # crossing from +0 to -0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** calculate counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:45:17.147161Z",
     "start_time": "2023-01-03T12:45:17.131452Z"
    }
   },
   "outputs": [],
   "source": [
    "train[\"zero+\"] = (mask.diff(axis=1) == 1).sum(axis=1)\n",
    "train[\"zero-\"] = (mask.diff(axis=1) == -1).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:45:24.034007Z",
     "start_time": "2023-01-03T12:45:24.027612Z"
    }
   },
   "outputs": [],
   "source": [
    "train[\"zero+\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** we do not need to perform any normalization, as all samples have the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:47:05.160622Z",
     "start_time": "2023-01-03T12:47:04.995570Z"
    }
   },
   "outputs": [],
   "source": [
    "train.loc[train[\"label\"]==1, \"zero+\"].plot(kind=\"hist\", range=(10, 50), label=\"class 1\")\n",
    "train.loc[train[\"label\"]==-1, \"zero+\"].plot(kind=\"hist\", range=(10, 50), alpha=0.6, label=\"class -1\")\n",
    "\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel(\"# 0+ crossings\")\n",
    "plt.ylabel(\"# samples\")\n",
    "plt.title(\"Distributions of 0-crossing counts (0+)\", fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:47:15.491011Z",
     "start_time": "2023-01-03T12:47:15.331542Z"
    }
   },
   "outputs": [],
   "source": [
    "train.loc[train[\"label\"]==1, \"zero-\"].plot(kind=\"hist\", range=(10, 50), label=\"class 1\")\n",
    "train.loc[train[\"label\"]==-1, \"zero-\"].plot(kind=\"hist\", range=(10, 50), alpha=0.6, label=\"class -1\")\n",
    "\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel(\"# 0- crossings\")\n",
    "plt.ylabel(\"# samples\")\n",
    "plt.title(\"Distributions of 0-crossing counts (0-)\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, for oscillatory time series `zero+` and `zero-` are highly correlated, so we may drop one of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:48:10.974768Z",
     "start_time": "2023-01-03T12:48:10.953085Z"
    }
   },
   "outputs": [],
   "source": [
    "train.filter(like=\"zero\").corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:48:36.656138Z",
     "start_time": "2023-01-03T12:48:36.643848Z"
    }
   },
   "outputs": [],
   "source": [
    "train.drop(\"zero-\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of `zero+` looks fancy, and ROC curve reflects that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:49:28.139884Z",
     "start_time": "2023-01-03T12:49:28.056895Z"
    }
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thr = roc_curve(train[\"label\"], -train[\"zero+\"])\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], \"--\", c=\"k\", linewidth=1)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC curve for zero+\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think on this in the following way.\n",
    "\n",
    "Look at the histograms, and perform an estimate (no code, just in your head): given, that `zero+` is equal to `v`, what is the probability of a sample to belong to class `1`? Is this probability monotonic with `v`? How does this influence the choice of the model? Will logistic regression do the job here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T13:00:03.572913Z",
     "start_time": "2023-01-03T13:00:03.565830Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot other features here - you may find various spectral features helpful here\n",
    "# perform an analysis similar to one we did with number of 0-crossings\n",
    "# beware of NaNs - some statistics may be broken for some rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: modeling\n",
    "\n",
    "Given all the features you selected in Tasks 2 and 3, create a binary  classification model. You need to perform:\n",
    "\n",
    "- reasonable train/validation split of `train`,\n",
    "- select a model type (out of those, available in `sklearn`, no need to go for, say, gradient boosting),\n",
    "- train a model, validate it and calculate the final score (ROC AUC) for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T13:04:29.073440Z",
     "start_time": "2023-01-03T13:04:29.067709Z"
    }
   },
   "outputs": [],
   "source": [
    "# do the train/validation split\n",
    "# train a model\n",
    "# check the performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "6d04047d2253f287091e9caf71fa3f6c1ebc788e61497cfe430ec057946d30f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
